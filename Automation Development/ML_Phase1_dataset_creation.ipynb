{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths to csv files and create dataframe for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravel_full_df = pd.DataFrame(columns = [\"dataset\", \"file_name\",'count', 'no clue', 'g2g', 'g18g', 'g50g', 'ppm', 'g200g', 'gX55g', 'gY55g', 'g250g']) # names columns)\n",
    "\n",
    "gravel_csv1 = r'C:\\Users\\elise\\Downloads\\Arolik_Output1-5.csv'\n",
    "gravel_csv2 = r\"C:\\Users\\elise\\Downloads\\Arolik_Output2-5.csv\"\n",
    "gravel_csv3 = r\"C:\\Users\\elise\\Downloads\\Arolik_Output3-5.csv\"\n",
    "gravel_csv4 = r\"C:\\Users\\elise\\Downloads\\Arolik_Output4-5.csv\"\n",
    "gravel_csv5 = r\"C:\\Users\\elise\\Downloads\\Arolik_Output5-5.csv\"\n",
    "\n",
    "gravel_df1 = pd.read_csv(gravel_csv1)\n",
    "gravel_df2 = pd.read_csv(gravel_csv2)\n",
    "gravel_df3 = pd.read_csv(gravel_csv3)\n",
    "gravel_df4 = pd.read_csv(gravel_csv4)\n",
    "gravel_df5 = pd.read_csv(gravel_csv5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravel_full_df = pd.concat([gravel_full_df, gravel_df1], ignore_index=True)\n",
    "gravel_full_df = pd.concat([gravel_full_df, gravel_df2], ignore_index=True)\n",
    "gravel_full_df = pd.concat([gravel_full_df, gravel_df3], ignore_index=True)\n",
    "gravel_full_df = pd.concat([gravel_full_df, gravel_df4], ignore_index=True)\n",
    "gravel_full_df = pd.concat([gravel_full_df, gravel_df5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dataset     file_name     count   no clue      g2g    g18g  \\\n",
      "0         Arolik_2023  bLog00AF.bin   3622785  -4194304  1478235  132561   \n",
      "1         Arolik_2023  bLog00AF.bin   3622786  -4194304  1489021  132499   \n",
      "2         Arolik_2023  bLog00AF.bin   3622787  -4194304  1489306  132424   \n",
      "3         Arolik_2023  bLog00AF.bin   3622788  -4194304  1488801  133053   \n",
      "4         Arolik_2023  bLog00AF.bin   3622789  -4194304  1476185  133188   \n",
      "...               ...           ...       ...       ...      ...     ...   \n",
      "34439995  Arolik_2023  bLog00F9.bin  -4154436  -4194304  1498016  132848   \n",
      "34439996  Arolik_2023  bLog00F9.bin  -4154435  -4194304  1494935  133984   \n",
      "34439997  Arolik_2023  bLog00F9.bin  -4154434  -4194304  1499515  134119   \n",
      "34439998  Arolik_2023  bLog00F9.bin  -4154433  -4194304  1502885  133811   \n",
      "34439999  Arolik_2023  bLog00F9.bin  -4154432  -4194304  1500203  133329   \n",
      "\n",
      "            g50g    ppm   g200g  gX55g   gY55g  g250g  \n",
      "0         296206  66443  319035  36307  160088  52375  \n",
      "1         296341  67728  319005  36937  157706  52171  \n",
      "2         298199  68454  318901  35334  159056  50794  \n",
      "3         299918  66845  318996  34318  161163  50997  \n",
      "4         301414  67014  319186  35890  159730  52136  \n",
      "...          ...    ...     ...    ...     ...    ...  \n",
      "34439995  302084  65054  305466  22525  153828  50582  \n",
      "34439996  300455  66593  305667  21099  155268  49803  \n",
      "34439997  298834  65581  305710  21227  153943  50446  \n",
      "34439998  297065  64401  305708  21120  151813  49548  \n",
      "34439999  298979  65194  305799  20921  152800  48791  \n",
      "\n",
      "[34440000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(gravel_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to the csv of drop names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "0    bLog00AF.bin\n",
      "1    bLog0078.bin\n",
      "2    bLog00F8.bin\n",
      "3    bLog0074.bin\n",
      "4    bLog009D.bin\n",
      "..            ...\n",
      "285  bLog0112.bin\n",
      "286  bLog00D4.bin\n",
      "287  bLog0050.bin\n",
      "288  bLog00F9.bin\n",
      "289  bLog0079.bin\n",
      "\n",
      "[290 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "gravel_names_df = pd.read_csv(r'C:\\Users\\elise\\Downloads\\Arolik_Drop_Names.csv')\n",
    "print(gravel_names_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if every recording belongs to a file with a drop, mark as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values in 'Value1' column of df1 are present in 'Value2' column of df2\n",
    "gravel_full_df['drop'] = gravel_full_df['file_name'].isin(gravel_names_df).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dataset     file_name     count   no clue      g2g    g18g  \\\n",
      "0         Arolik_2023  bLog00AF.bin   3622785  -4194304  1478235  132561   \n",
      "1         Arolik_2023  bLog00AF.bin   3622786  -4194304  1489021  132499   \n",
      "2         Arolik_2023  bLog00AF.bin   3622787  -4194304  1489306  132424   \n",
      "3         Arolik_2023  bLog00AF.bin   3622788  -4194304  1488801  133053   \n",
      "4         Arolik_2023  bLog00AF.bin   3622789  -4194304  1476185  133188   \n",
      "...               ...           ...       ...       ...      ...     ...   \n",
      "34439995  Arolik_2023  bLog00F9.bin  -4154436  -4194304  1498016  132848   \n",
      "34439996  Arolik_2023  bLog00F9.bin  -4154435  -4194304  1494935  133984   \n",
      "34439997  Arolik_2023  bLog00F9.bin  -4154434  -4194304  1499515  134119   \n",
      "34439998  Arolik_2023  bLog00F9.bin  -4154433  -4194304  1502885  133811   \n",
      "34439999  Arolik_2023  bLog00F9.bin  -4154432  -4194304  1500203  133329   \n",
      "\n",
      "            g50g    ppm   g200g  gX55g   gY55g  g250g  drop  \n",
      "0         296206  66443  319035  36307  160088  52375     0  \n",
      "1         296341  67728  319005  36937  157706  52171     0  \n",
      "2         298199  68454  318901  35334  159056  50794     0  \n",
      "3         299918  66845  318996  34318  161163  50997     0  \n",
      "4         301414  67014  319186  35890  159730  52136     0  \n",
      "...          ...    ...     ...    ...     ...    ...   ...  \n",
      "34439995  302084  65054  305466  22525  153828  50582     0  \n",
      "34439996  300455  66593  305667  21099  155268  49803     0  \n",
      "34439997  298834  65581  305710  21227  153943  50446     0  \n",
      "34439998  297065  64401  305708  21120  151813  49548     0  \n",
      "34439999  298979  65194  305799  20921  152800  48791     0  \n",
      "\n",
      "[34440000 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(gravel_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export full gravel dataframe to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravel_full_df.to_csv(r'C:\\Users\\elise\\Downloads\\Arolik_Full_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat for sands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sand_full_df = pd.DataFrame(columns = [\"dataset\", \"file_name\",'count', 'no clue', 'g2g', 'g18g', 'g50g', 'ppm', 'g200g', 'gX55g', 'gY55g', 'g250g']) # names columns)\n",
    "\n",
    "sand_csv1 = r'C:\\Users\\elise\\Downloads\\Duck_Output1-5.csv'\n",
    "sand_csv2 = r\"C:\\Users\\elise\\Downloads\\Duck_Output2-5.csv\"\n",
    "sand_csv3 = r\"C:\\Users\\elise\\Downloads\\Duck_Output3-5.csv\"\n",
    "sand_csv4 = r\"C:\\Users\\elise\\Downloads\\Duck_Output4-5.csv\"\n",
    "sand_csv5 = r\"C:\\Users\\elise\\Downloads\\Duck_Output5-5.csv\"\n",
    "\n",
    "sand_df1 = pd.read_csv(sand_csv1)\n",
    "sand_df2 = pd.read_csv(sand_csv2)\n",
    "sand_df3 = pd.read_csv(sand_csv3)\n",
    "sand_df4 = pd.read_csv(sand_csv4)\n",
    "sand_df5 = pd.read_csv(sand_csv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sand_full_df = pd.concat([sand_full_df, sand_df1], ignore_index=True)\n",
    "sand_full_df = pd.concat([sand_full_df, sand_df2], ignore_index=True)\n",
    "sand_full_df = pd.concat([sand_full_df, sand_df3], ignore_index=True)\n",
    "sand_full_df = pd.concat([sand_full_df, sand_df4], ignore_index=True)\n",
    "sand_full_df = pd.concat([sand_full_df, sand_df5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "0    bLog024D.bin\n",
      "1    bLog0240.bin\n",
      "2    bLog01F0.bin\n",
      "3    bLog028F.bin\n",
      "4    bLog0269.bin\n",
      "..            ...\n",
      "253  bLog0216.bin\n",
      "254  bLog022A.bin\n",
      "255  bLog01FF.bin\n",
      "256  bLog020E.bin\n",
      "257  bLog0200.bin\n",
      "\n",
      "[258 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "sand_names_df = pd.read_csv(r'C:\\Users\\elise\\Downloads\\Duck_Drop_Names.csv')\n",
    "print(sand_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dataset     file_name     count   no clue      g2g    g18g  \\\n",
      "0         Duck_2023  bLog024D.bin    165569  -4194304  1469739  130660   \n",
      "1         Duck_2023  bLog024D.bin    165570  -4194304  1460896  130313   \n",
      "2         Duck_2023  bLog024D.bin    165571  -4194304  1439371  129866   \n",
      "3         Duck_2023  bLog024D.bin    165572  -4194304  1425869  129051   \n",
      "4         Duck_2023  bLog024D.bin    165573  -4194304  1425646  127409   \n",
      "...             ...           ...       ...       ...      ...     ...   \n",
      "30599995  Duck_2023  bLog020E.bin  -7274436  -4194304  1722657  157383   \n",
      "30599996  Duck_2023  bLog020E.bin  -7274435  -4194304  1700309  154738   \n",
      "30599997  Duck_2023  bLog020E.bin  -7274434  -4194304  1690116  154140   \n",
      "30599998  Duck_2023  bLog020E.bin  -7274433  -4194304  1694349  154312   \n",
      "30599999  Duck_2023  bLog020E.bin  -7274432  -4194304  1695511  154232   \n",
      "\n",
      "            g50g    ppm   g200g  gX55g   gY55g  g250g  drop  \n",
      "0         297276  76424  320929  92311  146849  51428     0  \n",
      "1         297433  79184  320944  87928  149576  51949     0  \n",
      "2         298163  79655  320661  88417  151694  52283     0  \n",
      "3         298751  79124  320241  88424  152413  52682     0  \n",
      "4         299327  80191  320074  88799  153027  51576     0  \n",
      "...          ...    ...     ...    ...     ...    ...   ...  \n",
      "30599995  307437  81811  325141  44408  150489  54109     0  \n",
      "30599996  306369  81279  324771  43796  148803  54744     0  \n",
      "30599997  305596  79919  324503  42867  148403  55734     0  \n",
      "30599998  304141  79196  324274  42295  148869  55394     0  \n",
      "30599999  302069  80502  324233  40409  146683  54869     0  \n",
      "\n",
      "[30600000 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "sand_full_df['drop'] = sand_full_df['file_name'].isin(sand_names_df).astype(int)\n",
    "print(sand_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sand_full_df.to_csv(r'C:\\Users\\elise\\Downloads\\Duck_Full_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clay_full_df = pd.DataFrame(columns = [\"dataset\", \"file_name\",'count', 'no clue', 'g2g', 'g18g', 'g50g', 'ppm', 'g200g', 'gX55g', 'gY55g', 'g250g']) # names columns)\n",
    "\n",
    "clay_csv1 = r'C:\\Users\\elise\\Downloads\\Sequim_Output1-5.csv'\n",
    "clay_csv2 = r\"C:\\Users\\elise\\Downloads\\Sequim_Output2-5.csv\"\n",
    "clay_csv3 = r\"C:\\Users\\elise\\Downloads\\Sequim_Output3-5.csv\"\n",
    "clay_csv4 = r\"C:\\Users\\elise\\Downloads\\Sequim_Output4-5.csv\"\n",
    "clay_csv5 = r\"C:\\Users\\elise\\Downloads\\Sequim_Output5-5.csv\"\n",
    "\n",
    "clay_df1 = pd.read_csv(clay_csv1)\n",
    "clay_df2 = pd.read_csv(clay_csv2)\n",
    "clay_df3 = pd.read_csv(clay_csv3)\n",
    "clay_df4 = pd.read_csv(clay_csv4)\n",
    "clay_df5 = pd.read_csv(clay_csv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clay_full_df = pd.concat([clay_full_df, clay_df1], ignore_index=True)\n",
    "clay_full_df = pd.concat([clay_full_df, clay_df2], ignore_index=True)\n",
    "clay_full_df = pd.concat([clay_full_df, clay_df3], ignore_index=True)\n",
    "clay_full_df = pd.concat([clay_full_df, clay_df4], ignore_index=True)\n",
    "clay_full_df = pd.concat([clay_full_df, clay_df5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "0    bLog03A0.bin\n",
      "1    bLog03F7.bin\n",
      "2    bLog024D.bin\n",
      "3    bLog0359.bin\n",
      "4    bLog0444.bin\n",
      "..            ...\n",
      "692  bLog03AB.bin\n",
      "693  bLog0413.bin\n",
      "694  bLog01FF.bin\n",
      "695  bLog020E.bin\n",
      "696  bLog0200.bin\n",
      "\n",
      "[697 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "clay_names_df = pd.read_csv(r'C:\\Users\\elise\\Downloads\\Sequim_Drop_Names.csv')\n",
    "print(clay_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dataset     file_name     count   no clue      g2g    g18g  \\\n",
      "0         Sequim_2021  bLog03A0.bin  -4034431  -4194304  1441103  129378   \n",
      "1         Sequim_2021  bLog03A0.bin  -4034430  -4194304  1446383  128947   \n",
      "2         Sequim_2021  bLog03A0.bin  -4034429  -4194304  1452913  129749   \n",
      "3         Sequim_2021  bLog03A0.bin  -4034428  -4194304  1452101  130631   \n",
      "4         Sequim_2021  bLog03A0.bin  -4034427  -4194304  1446652  130924   \n",
      "...               ...           ...       ...       ...      ...     ...   \n",
      "35999995  Sequim_2021  bLog02A4.bin  -4206084  -4194304  -248599  -42499   \n",
      "35999996  Sequim_2021  bLog02A4.bin  -4206083  -4194304  -243242  -41863   \n",
      "35999997  Sequim_2021  bLog02A4.bin  -4206082  -4194304  -245871  -42112   \n",
      "35999998  Sequim_2021  bLog02A4.bin  -4206081  -4194304  -245836  -42927   \n",
      "35999999  Sequim_2021  bLog02A4.bin  -4206080  -4194304  -251899  -42376   \n",
      "\n",
      "            g50g    ppm   g200g  gX55g   gY55g  g250g  drop  \n",
      "0         301261  59453  316384  30853  159886  53026     0  \n",
      "1         299831  59630  316517  30082  159056  52683     0  \n",
      "2         297788  58718  316758  28965  156644  51241     0  \n",
      "3         298203  58499  316440  29233  155818  50649     0  \n",
      "4         299074  59098  316331  29244  155938  51419     0  \n",
      "...          ...    ...     ...    ...     ...    ...   ...  \n",
      "35999995  230765  49679  272998   9944  185531  38607     0  \n",
      "35999996  229730  51000  272811   9408  184767  39099     0  \n",
      "35999997  229152  51797  272951  10278  183506  39327     0  \n",
      "35999998  228414  51972  272936  13032  184702  37802     0  \n",
      "35999999  227086  51443  273045  12309  183506  37923     0  \n",
      "\n",
      "[36000000 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "clay_full_df['drop'] = clay_full_df['file_name'].isin(clay_names_df).astype(int)\n",
    "print(clay_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clay_full_df.to_csv(r'C:\\Users\\elise\\Downloads\\Sequim_Full_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
